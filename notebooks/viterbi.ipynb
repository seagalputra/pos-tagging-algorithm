{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Define All Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    \"\"\"Fungsi untuk melakukan load data pada file .tsv maupun .txt\n",
    "    \n",
    "    File yang digunakan yaitu file .tsv maupun file yang mampu dibuka\n",
    "    menggunakan teks editor. Dalam file tersebut terdapat tag pembuka <kalimat>\n",
    "    dan diakhiri tag penutup </kalimat> yang berfungsi sebagai penanda bahwa\n",
    "    entitas tersebut termasuk ke dalam satu kalimat.\n",
    "    \n",
    "    Args:\n",
    "        filename: string dari nama file yang akan diload datanya.\n",
    "        \n",
    "    Return:\n",
    "        list dari kata-kata dan tags dengan index yang menunjukkan posisi kalimat tersebut.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data dan buka sebagai file\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    with open(filename) as file:\n",
    "        contents = file.readlines()\n",
    "\n",
    "    # Hapus karakter \\n yang tidak dibutuhkan\n",
    "    contents = [content.strip() for content in contents]\n",
    "    idx = 0\n",
    "    while idx < len(contents):\n",
    "        word = []\n",
    "        tag = []\n",
    "        # looping sampai menemukan pattern dengan awalan </kalimat\n",
    "        while not contents[idx].startswith('</kalimat'):\n",
    "            # kondisi jika menemukan sebuah data yang tidak memiliki awalan <kalimat\n",
    "            if not contents[idx].startswith('<kalimat'):\n",
    "                temp_word, temp_tag = contents[idx].split(\"\\t\")\n",
    "                word.append(temp_word.lower())\n",
    "                tag.append(temp_tag)\n",
    "            idx += 1\n",
    "        sentences.append(word)\n",
    "        tags.append(tag)\n",
    "        idx += 2\n",
    "        \n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(multi_list):\n",
    "    \"\"\"Mengembalikan list multi dimensi ke dalam list satu dimensi.\n",
    "    \n",
    "    Input list yang masuk di proses menggunakan method from_iterable dari\n",
    "    package itertools dan mengembalikan object berupa generator yang iterable.\n",
    "    \n",
    "    Args:\n",
    "        multi_list: list multi dimensi.\n",
    "    \n",
    "    Return:\n",
    "        list satu dimensi yang nantinya digunakan untuk pemrosesan lebih lanjut.\n",
    "    \"\"\"\n",
    "    \n",
    "    return chain.from_iterable(multi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram(dataset):\n",
    "    \"\"\"Fungsi untuk membuat bigram dari list.\n",
    "    \n",
    "    Input list berisi string yang nantinya digenerate bigram dan mengembalikan\n",
    "    objek berupa dictionary python.\n",
    "    \n",
    "    Args:\n",
    "        dataset: list satu dimensi.\n",
    "        \n",
    "    Return:\n",
    "        dictionary yang memuat bigram dan banyaknya bigram pada list tersebut.\n",
    "    \"\"\"\n",
    "    \n",
    "    bigrams = []\n",
    "    for i in range(len(dataset)-1):\n",
    "        bigrams.append((dataset[i], dataset[i+1]))\n",
    "    count_bigrams = Counter(bigrams)\n",
    "    \n",
    "    return bigrams, dict(count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_transition(dict_bigrams):\n",
    "    \"\"\"Fungsi untuk menghitung probabilitas dari dictionary perhitungan banyaknya muncul pasangan tag\n",
    "    \n",
    "    Tag diambil dan dihitung berdasarkan banyak kemunculan dibagi dengan total keseluruhan tag\n",
    "    yang muncul.\n",
    "    \n",
    "    Args:\n",
    "        dict_bigrams: dictionary berisi pasangan tag dan banyaknya kemunculan tag\n",
    "    \n",
    "    Return:\n",
    "        tabel transisi yang berisi probabilitas kemunculan tag dan tag berikutnya\n",
    "    \n",
    "    \"\"\"\n",
    "    probs = []\n",
    "    keys = []\n",
    "    \n",
    "    for states, value in count_bigrams.items():\n",
    "        total_cnt = 0\n",
    "        for sts in count_bigrams.keys():\n",
    "            if states[0] == sts[0]:\n",
    "                total_cnt += count_bigrams[sts]\n",
    "        prob = value / total_cnt\n",
    "        probs.append(prob)\n",
    "        keys.append(states)\n",
    "        \n",
    "    probs_transition = dict(zip(keys,probs))\n",
    "    return probs_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unneeded_states(count_bigrams):\n",
    "    \"\"\"Fungsi untuk menghilangkan states X -> <s>\n",
    "    \n",
    "    Dimana X adalah state apapun. Dihilangkan karena tidak dibutuhkan pada representasi transition\n",
    "    table juga pada implementasi algoritma Viterbi\n",
    "    \n",
    "    Args:\n",
    "        count_bigrams: dictionary berisi pasangan tag dan banyaknya kemunculan tag\n",
    "    \n",
    "    Return:\n",
    "        dictionary berisi pasangan tags dan kemunculuannya tanpa beberapa pasang tags tertentu\n",
    "    \n",
    "    \"\"\"\n",
    "    terminated_states = []\n",
    "    for states in count_bigrams.keys():\n",
    "        if states[1] == \"<s>\":\n",
    "            terminated_states.append(states)\n",
    "\n",
    "    for states in terminated_states:\n",
    "        del count_bigrams[states]\n",
    "    return count_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_sentence_beginning(tags_train):\n",
    "    \"\"\"Fungsi untuk menambahkan <s> pada setiap awal kalimat\n",
    "    \n",
    "    Args:\n",
    "        tags_train: list dua dimensi berisikan list yang merepresentasikan satu kalimat\n",
    "    \n",
    "    Return:\n",
    "        list dua dimensi yang terdapat penanda awal kalimat pada setiap kalimat\n",
    "    \n",
    "    \"\"\"\n",
    "    for sentence in tags_train:\n",
    "        sentence.insert(0, '<s>')\n",
    "    return tags_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission_table(words, tags):\n",
    "# Membuat representasi tabel emission probability dari HMM\n",
    "    hidden_state = {}\n",
    "    for word in words:\n",
    "        # Jika word belum pernah ditemui maka akan digenerate\n",
    "        # tagset berserta probabilitasnya\n",
    "        if word not in hidden_state.keys():\n",
    "            word_tags = []\n",
    "            for idx, wrd in enumerate(words):\n",
    "                if wrd == word :\n",
    "                    word_tags.append(tags[idx])\n",
    "            # Membuat dictionary berisi semua tagset dari sebauh word\n",
    "            # pada korpus. Berserta jumlah kemunculan setiap tagsetnya\n",
    "            tag_count = {}\n",
    "            for tag in word_tags:\n",
    "                if tag not in tag_count.keys():\n",
    "                    tag_count[tag] = 1\n",
    "                else:\n",
    "                    tag_count[tag] += 1\n",
    "            total = 0\n",
    "            # Mengubah jumlah kemunculan menjadi probabilitas\n",
    "            tag_prob = {}\n",
    "            for count in tag_count.values():\n",
    "                total += count\n",
    "            for tagset in tag_count.keys():\n",
    "                tag_prob[tagset] = tag_count[tagset]/total\n",
    "            hidden_state[word] = tag_prob\n",
    "        else:\n",
    "            # Jika word sudah pernah ditemui maka akan dilewati\n",
    "            continue\n",
    "    return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_emission():\n",
    "    file_path = \"../data/\"\n",
    "    file_name = \"Indonesian_Manually_Tagged_Corpus_ID.tsv\"\n",
    "    words, tags = get_data(file_path + file_name)\n",
    "    words = list(flatten(words))[:1000]\n",
    "    tags = list(flatten(tags))[:1000]\n",
    "    return words, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags_viterbi(sentence, emission_table, transition_table):\n",
    "    viterbi_probs = []\n",
    "    for i in range(1, len(sentence)):\n",
    "        viterbi_probs.append(\"tmp\")\n",
    "    viterbi_path = []\n",
    "    viterbi_prob_count = 0\n",
    "    for idx, word in enumerate(sentence):\n",
    "        if word == \"<s>\":\n",
    "            continue\n",
    "        else:\n",
    "            for key_word, em_prob in emission_table.items():\n",
    "                tmp_probs = []\n",
    "                tmp_tags = []\n",
    "                if key_word == word:\n",
    "                    for tag, prob in em_prob.items():\n",
    "                        tmp_tags.append(tag)\n",
    "                        tmp_probs.append(prob)\n",
    "                    if sentence[idx-1] == \"<s>\":\n",
    "                        viterbi_path.append(\"<s>\")\n",
    "                        tmp = 0\n",
    "                        tmp_idx_path = 0\n",
    "                        tmp_idx_prob = 0\n",
    "                        for sts, tr_prob in transition_table.items():\n",
    "                            for idx, tag in enumerate(tmp_tags):\n",
    "                                if viterbi_path[0] == sts[0] and tag == sts[1]:\n",
    "                                    viterbi_prob = tmp_probs[idx] * tr_prob\n",
    "                                    if tmp < viterbi_prob:\n",
    "                                        tmp = viterbi_prob\n",
    "                                        tmp_idx_path = idx\n",
    "                                        viterbi_probs[viterbi_prob_count] = viterbi_prob\n",
    "                                        viterbi_prob_count += 1\n",
    "    #                             else:\n",
    "    #                                 viterbi_path.append(\"NN\")\n",
    "    #                                 if viterbi_path[0] == sts[0] and \"NN\" == sts[1]:\n",
    "    #                                     viterbi_prob = tmp_probs[idx] * tr_prob\n",
    "    #                                     if tmp < viterbi_prob:\n",
    "    #                                         tmp = viterbi_prob\n",
    "    #                                         tmp_idx_path = idx\n",
    "    #                                         viterbi_probs[viterbi_prob_count] = viterbi_prob\n",
    "    #                                         viterbi_prob_count += 1\n",
    "                        viterbi_path.append(tmp_tags[tmp_idx_path])\n",
    "                    else:\n",
    "                        tmp = 0\n",
    "                        tmp_idx_path = 0\n",
    "                        tmp_idx_prob = 0\n",
    "                        for sts, tr_prob in transition_table.items():\n",
    "                            for idx, tag in enumerate(tmp_tags):\n",
    "                                if viterbi_path[-1] == sts[0] and tag == sts[1]:\n",
    "                                    viterbi_prob = viterbi_probs[viterbi_prob_count-1] \\\n",
    "                                    * tmp_probs[idx] * tr_prob\n",
    "                                    if tmp < viterbi_prob:\n",
    "                                        tmp = viterbi_prob\n",
    "                                        tmp_idx_path = idx\n",
    "                                        viterbi_probs[viterbi_prob_count] = viterbi_prob\n",
    "                                        viterbi_prob_count += 1\n",
    "                                #else: backtrack       \n",
    "                        viterbi_path.append(tmp_tags[tmp_idx_path])\n",
    "    return viterbi_probs[-1], viterbi_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Separate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dan pisahkan dataset sebanyak 1000 data train dan 20 data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/corpus.tsv'\n",
    "sentences, tags = get_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil 1020 data awal\n",
    "data_train, data_test, tags_train, tags_test = sentences[:1000], sentences[1000:1020], tags[:1000], tags[1000:1020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabel transisi dibuat berdasarkan data train yang telah diambil pada corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_train = insert_sentence_beginning(tags_train)\n",
    "tags_train = list(flatten(tags_train))\n",
    "bigrams, count_bigrams = get_bigram(tags_train)\n",
    "count_bigrams = remove_unneeded_states(count_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = load_dataset_emission()\n",
    "emission_table = get_emission_table(words, tags)\n",
    "transition_table = get_prob_transition(count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-409-7276a995dc30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tags_viterbi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memission_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransition_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-401-7300423425a7>\u001b[0m in \u001b[0;36mget_tags_viterbi\u001b[1;34m(sentence, emission_table, transition_table)\u001b[0m\n\u001b[0;32m     46\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0msts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_prob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransition_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_tags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                                 \u001b[1;32mif\u001b[0m \u001b[0mviterbi_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m                                     \u001b[0mviterbi_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mviterbi_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mviterbi_prob_count\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m                                     \u001b[1;33m*\u001b[0m \u001b[0mtmp_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtr_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                                     \u001b[1;32mif\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mviterbi_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "final_prob, final_path = get_tags_viterbi(test, emission_table, transition_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "menurut\n",
      "pefindo\n",
      ",\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-460-e6e322745911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0msts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_prob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransition_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_tags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                             \u001b[1;32mif\u001b[0m \u001b[0mviterbi_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m                                 \u001b[0mviterbi_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mviterbi_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mviterbi_prob_count\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m                                 \u001b[1;33m*\u001b[0m \u001b[0mtmp_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtr_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mviterbi_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "viterbi_probs = []\n",
    "for i in range(1, len(test)):\n",
    "    viterbi_probs.append(\"tmp\")\n",
    "viterbi_path = []\n",
    "viterbi_prob_count = 0\n",
    "for idx, word in enumerate(test):\n",
    "    print(word)\n",
    "    if word == \"<s>\":\n",
    "        continue\n",
    "    else:\n",
    "        for key_word, em_prob in emission_table.items():\n",
    "            tmp_probs = []\n",
    "            tmp_tags = []\n",
    "            if key_word == word:\n",
    "                for tag, prob in em_prob.items():\n",
    "                    tmp_tags.append(tag)\n",
    "                    tmp_probs.append(prob)\n",
    "                if test[idx-1] == \"<s>\":\n",
    "                    viterbi_path.append(\"<s>\")\n",
    "                    tmp = 0\n",
    "                    tmp_idx_path = 0\n",
    "                    tmp_idx_prob = 0\n",
    "                    for sts, tr_prob in transition_table.items():\n",
    "                        for idx, tag in enumerate(tmp_tags):\n",
    "                            if viterbi_path[0] == sts[0] and tag == sts[1]:\n",
    "                                viterbi_prob = tmp_probs[idx] * tr_prob\n",
    "                                if tmp < viterbi_prob:\n",
    "                                    tmp = viterbi_prob\n",
    "                                    tmp_idx_path = idx\n",
    "                                    viterbi_probs[viterbi_prob_count] = viterbi_prob\n",
    "                                    viterbi_prob_count += 1\n",
    "    #                             else:\n",
    "    #                                 viterbi_path.append(\"NN\")\n",
    "    #                                 if viterbi_path[0] == sts[0] and \"NN\" == sts[1]:\n",
    "    #                                     viterbi_prob = tmp_probs[idx] * tr_prob\n",
    "    #                                     if tmp < viterbi_prob:\n",
    "    #                                         tmp = viterbi_prob\n",
    "    #                                         tmp_idx_path = idx\n",
    "    #                                         viterbi_probs[viterbi_prob_count] = viterbi_prob\n",
    "    #                                         viterbi_prob_count += 1\n",
    "                    viterbi_path.append(tmp_tags[tmp_idx_path])\n",
    "                else:\n",
    "                    tmp = 0\n",
    "                    tmp_idx_path = 0\n",
    "                    tmp_idx_prob = 0\n",
    "                    for sts, tr_prob in transition_table.items():\n",
    "                        for idx, tag in enumerate(tmp_tags):\n",
    "                            if viterbi_path[-1] == sts[0] and tag == sts[1]:\n",
    "                                viterbi_prob = viterbi_probs[viterbi_prob_count-1] \\\n",
    "                                * tmp_probs[idx] * tr_prob\n",
    "                                if tmp < viterbi_prob:\n",
    "                                    tmp = viterbi_prob\n",
    "                                    tmp_idx_path = idx\n",
    "                                    viterbi_probs[viterbi_prob_count] = viterbi_prob\n",
    "                                    viterbi_prob_count += 1\n",
    "                                #else: backtrack       \n",
    "                    viterbi_path.append(tmp_tags[tmp_idx_path])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
