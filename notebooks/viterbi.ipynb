{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Define All Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    \"\"\"Fungsi untuk melakukan load data pada file .tsv maupun .txt\n",
    "    \n",
    "    File yang digunakan yaitu file .tsv maupun file yang mampu dibuka\n",
    "    menggunakan teks editor. Dalam file tersebut terdapat tag pembuka <kalimat>\n",
    "    dan diakhiri tag penutup </kalimat> yang berfungsi sebagai penanda bahwa\n",
    "    entitas tersebut termasuk ke dalam satu kalimat.\n",
    "    \n",
    "    Args:\n",
    "        filename: string dari nama file yang akan diload datanya.\n",
    "        \n",
    "    Return:\n",
    "        list dari kata-kata dan tags dengan index yang menunjukkan posisi kalimat tersebut.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data dan buka sebagai file\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    with open(filename) as file:\n",
    "        contents = file.readlines()\n",
    "\n",
    "    # Hapus karakter \\n yang tidak dibutuhkan\n",
    "    contents = [content.strip() for content in contents]\n",
    "    idx = 0\n",
    "    while idx < len(contents):\n",
    "        word = []\n",
    "        tag = []\n",
    "        # looping sampai menemukan pattern dengan awalan </kalimat\n",
    "        while not contents[idx].startswith('</kalimat'):\n",
    "            # kondisi jika menemukan sebuah data yang tidak memiliki awalan <kalimat\n",
    "            if not contents[idx].startswith('<kalimat'):\n",
    "                temp_word, temp_tag = contents[idx].split(\"\\t\")\n",
    "                word.append(temp_word.lower())\n",
    "                tag.append(temp_tag)\n",
    "            idx += 1\n",
    "        sentences.append(word)\n",
    "        tags.append(tag)\n",
    "        idx += 2\n",
    "        \n",
    "    return sentences, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(multi_list):\n",
    "    \"\"\"Mengembalikan list multi dimensi ke dalam list satu dimensi.\n",
    "    \n",
    "    Input list yang masuk di proses menggunakan method from_iterable dari\n",
    "    package itertools dan mengembalikan object berupa generator yang iterable.\n",
    "    \n",
    "    Args:\n",
    "        multi_list: list multi dimensi.\n",
    "    \n",
    "    Return:\n",
    "        list satu dimensi yang nantinya digunakan untuk pemrosesan lebih lanjut.\n",
    "    \"\"\"\n",
    "    \n",
    "    return chain.from_iterable(multi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram(dataset):\n",
    "    \"\"\"Fungsi untuk membuat bigram dari list.\n",
    "    \n",
    "    Input list berisi string yang nantinya digenerate bigram dan mengembalikan\n",
    "    objek berupa dictionary python.\n",
    "    \n",
    "    Args:\n",
    "        dataset: list satu dimensi.\n",
    "        \n",
    "    Return:\n",
    "        dictionary yang memuat bigram dan banyaknya bigram pada list tersebut.\n",
    "    \"\"\"\n",
    "    \n",
    "    bigrams = []\n",
    "    for i in range(len(dataset)-1):\n",
    "        bigrams.append((dataset[i], dataset[i+1]))\n",
    "    count_bigrams = Counter(bigrams)\n",
    "    \n",
    "    return bigrams, dict(count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_transition(dict_bigrams):\n",
    "    \"\"\"Fungsi untuk menghitung probabilitas dari dictionary perhitungan banyaknya muncul pasangan tag\n",
    "    \n",
    "    Tag diambil dan dihitung berdasarkan banyak kemunculan dibagi dengan total keseluruhan tag\n",
    "    yang muncul.\n",
    "    \n",
    "    Args:\n",
    "        dict_bigrams: dictionary berisi pasangan tag dan banyaknya kemunculan tag\n",
    "    \n",
    "    Return:\n",
    "        tabel transisi yang berisi probabilitas kemunculan tag dan tag berikutnya\n",
    "    \n",
    "    \"\"\"\n",
    "    probs = []\n",
    "    keys = []\n",
    "    \n",
    "    for states, value in count_bigrams.items():\n",
    "        total_cnt = 0\n",
    "        for sts in count_bigrams.keys():\n",
    "            if states[0] == sts[0]:\n",
    "                total_cnt += count_bigrams[sts]\n",
    "        prob = value / total_cnt\n",
    "        probs.append(prob)\n",
    "        keys.append(states)\n",
    "        \n",
    "    probs_transition = dict(zip(keys,probs))\n",
    "    return probs_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unneeded_states(count_bigrams):\n",
    "    \"\"\"Fungsi untuk menghilangkan states X -> <s>\n",
    "    \n",
    "    Dimana X adalah state apapun. Dihilangkan karena tidak dibutuhkan pada representasi transition\n",
    "    table juga pada implementasi algoritma Viterbi\n",
    "    \n",
    "    Args:\n",
    "        count_bigrams: dictionary berisi pasangan tag dan banyaknya kemunculan tag\n",
    "    \n",
    "    Return:\n",
    "        dictionary berisi pasangan tags dan kemunculuannya tanpa beberapa pasang tags tertentu\n",
    "    \n",
    "    \"\"\"\n",
    "    terminated_states = []\n",
    "    for states in count_bigrams.keys():\n",
    "        if states[1] == \"<s>\":\n",
    "            terminated_states.append(states)\n",
    "\n",
    "    for states in terminated_states:\n",
    "        del count_bigrams[states]\n",
    "    return count_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_sentence_beginning(tags_train):\n",
    "    \"\"\"Fungsi untuk menambahkan <s> pada setiap awal kalimat\n",
    "    \n",
    "    Args:\n",
    "        tags_train: list dua dimensi berisikan list yang merepresentasikan satu kalimat\n",
    "    \n",
    "    Return:\n",
    "        list dua dimensi yang terdapat penanda awal kalimat pada setiap kalimat\n",
    "    \n",
    "    \"\"\"\n",
    "    for sentence in tags_train:\n",
    "        sentence.insert(0, '<s>')\n",
    "    return tags_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emission_table(words, tags):\n",
    "# Membuat representasi tabel emission probability dari HMM\n",
    "    hidden_state = {}\n",
    "    for word in words:\n",
    "        # Jika word belum pernah ditemui maka akan digenerate\n",
    "        # tagset berserta probabilitasnya\n",
    "        if word not in hidden_state.keys():\n",
    "            word_tags = []\n",
    "            for idx, wrd in enumerate(words):\n",
    "                if wrd == word :\n",
    "                    word_tags.append(tags[idx])\n",
    "            # Membuat dictionary berisi semua tagset dari sebauh word\n",
    "            # pada korpus. Berserta jumlah kemunculan setiap tagsetnya\n",
    "            tag_count = {}\n",
    "            for tag in word_tags:\n",
    "                if tag not in tag_count.keys():\n",
    "                    tag_count[tag] = 1\n",
    "                else:\n",
    "                    tag_count[tag] += 1\n",
    "            total = 0\n",
    "            # Mengubah jumlah kemunculan menjadi probabilitas\n",
    "            tag_prob = {}\n",
    "            for count in tag_count.values():\n",
    "                total += count\n",
    "            for tagset in tag_count.keys():\n",
    "                tag_prob[tagset] = tag_count[tagset]/total\n",
    "            hidden_state[word] = tag_prob\n",
    "        else:\n",
    "            # Jika word sudah pernah ditemui maka akan dilewati\n",
    "            continue\n",
    "    return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_emission():\n",
    "    file_path = \"../data/\"\n",
    "    file_name = \"Indonesian_Manually_Tagged_Corpus_ID.tsv\"\n",
    "    words, tags = get_data(file_path + file_name)\n",
    "    words = list(flatten(words))[:1000]\n",
    "    tags = list(flatten(tags))[:1000]\n",
    "    return words, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags_viterbi(sentence, emission_table, transition_table):\n",
    "    viterbi_probs = []\n",
    "    for i in range(1, len(sentence)):\n",
    "        viterbi_probs.append(\"tmp\")\n",
    "    viterbi_path = []\n",
    "    viterbi_prob_count = 0\n",
    "    for idx, word in enumerate(sentence):\n",
    "        if word == \"<s>\":\n",
    "            continue\n",
    "        else:\n",
    "            for key_word, em_prob in emission_table.items():\n",
    "                tmp_probs = []\n",
    "                tmp_tags = []\n",
    "                if key_word == word:\n",
    "                    for tag, prob in em_prob.items():\n",
    "                        tmp_tags.append(tag)\n",
    "                        tmp_probs.append(prob)\n",
    "                    if sentence[idx-1] == \"<s>\":\n",
    "                        viterbi_path.append(\"<s>\")\n",
    "                        tmp = 0\n",
    "                        tmp_idx_path = 0\n",
    "                        tmp_idx_prob = 0\n",
    "                        for sts, tr_prob in transition_table.items():\n",
    "                            for idx, tag in enumerate(tmp_tags):\n",
    "                                if viterbi_path[0] == sts[0] and tag == sts[1]:\n",
    "                                    viterbi_prob = tmp_probs[idx] * tr_prob\n",
    "                                    if tmp < viterbi_prob:\n",
    "                                        tmp = viterbi_prob\n",
    "                                        tmp_idx_path = idx\n",
    "                                        viterbi_probs[viterbi_prob_count] = viterbi_prob\n",
    "                                        viterbi_prob_count += 1\n",
    "                        viterbi_path.append(tmp_tags[tmp_idx_path])\n",
    "                    else:\n",
    "                        tmp = 0\n",
    "                        tmp_idx_path = 0\n",
    "                        tmp_idx_prob = 0\n",
    "                        for sts, tr_prob in transition_table.items():\n",
    "                            for idx, tag in enumerate(tmp_tags):\n",
    "                                if viterbi_path[-1] == sts[0] and tag == sts[1]:\n",
    "                                    viterbi_prob = viterbi_probs[viterbi_prob_count-1] \\\n",
    "                                    * tmp_probs[idx] * tr_prob\n",
    "                                    if tmp < viterbi_prob:\n",
    "                                        tmp = viterbi_prob\n",
    "                                        tmp_idx_path = idx\n",
    "                                        viterbi_probs[viterbi_prob_count] = viterbi_prob\n",
    "                                        viterbi_prob_count += 1\n",
    "                                #else: backtrack       \n",
    "                        viterbi_path.append(tmp_tags[tmp_idx_path])\n",
    "                else:\n",
    "                    break\n",
    "    if len(viterbi_path) == 0:\n",
    "        print(\"Kata pertama tidak terdapat di korpus\")\n",
    "        return viterbi_probs, viterbi_path\n",
    "    return viterbi_probs[-1], viterbi_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Separate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dan pisahkan dataset sebanyak 1000 data train dan 20 data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/corpus.tsv'\n",
    "sentences, tags = get_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil 1020 data awal\n",
    "data_train, data_test, tags_train, tags_test = sentences[:1000], sentences[1000:1020], tags[:1000], tags[1000:1020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabel transisi dibuat berdasarkan data train yang telah diambil pada corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_train = insert_sentence_beginning(tags_train)\n",
    "tags_train = list(flatten(tags_train))\n",
    "bigrams, count_bigrams = get_bigram(tags_train)\n",
    "count_bigrams = remove_unneeded_states(count_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = load_dataset_emission()\n",
    "emission_table = get_emission_table(words, tags)\n",
    "transition_table = get_prob_transition(count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_final = []\n",
    "for test in data_test:\n",
    "    data_test_final.insert(0, \"<s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Number 0: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 1: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 2: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 3: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 4: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 5: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 6: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 7: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 8: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 9: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 10: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 11: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 12: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 13: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 14: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 15: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 16: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 17: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 18: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n",
      "Test Number 19: \n",
      "<s>\n",
      "Kata pertama tidak terdapat di korpus\n",
      "Tag predictions: \n"
     ]
    }
   ],
   "source": [
    "for test_number, test in enumerate(data_test_final):\n",
    "    print(\"Test Number \" + str(test_number) + \": \")\n",
    "    print(test)\n",
    "    final_prob, final_path = get_tags_viterbi(test, emission_table, transition_table)\n",
    "    print(\"Tag predictions: \")\n",
    "    for tag in final_path:\n",
    "        print(tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
